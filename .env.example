# Local Deep Researcher Configuration
# Copy this file to .env and add your API keys

# ==========================================
# IMPORTANT: Search API Configuration
# ==========================================
# Tavily is STRONGLY RECOMMENDED for quality results
# DuckDuckGo often returns irrelevant results (charity pages, dictionaries, etc.)

SEARCH_API=tavily  # Options: tavily (recommended), perplexity, searxng, duckduckgo (poor quality)

# Get your free Tavily API key at https://tavily.com (100 searches/month free)
TAVILY_API_KEY=tvly-YOUR_KEY_HERE

# Alternative search APIs (uncomment if using)
# PERPLEXITY_API_KEY=pplx-YOUR_KEY_HERE  # https://www.perplexity.ai/settings/api
# SEARXNG_URL=http://localhost:8888      # Self-hosted SearXNG instance

# ==========================================
# LLM Configuration
# ==========================================
LLM_PROVIDER=ollama  # Options: ollama, lmstudio

# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434
LOCAL_LLM=llama3.1:8b  # Models: llama3.1:8b, deepseek-r1:8b, phi4:latest, etc.

# LMStudio settings (if using instead of Ollama)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LOCAL_LLM=your-model-name

# ==========================================
# Research Configuration
# ==========================================
MAX_WEB_RESEARCH_LOOPS=3
FETCH_FULL_PAGE=false  # Set to true for more comprehensive but slower research

# ==========================================
# Source Validation (NEW!)
# ==========================================
MIN_SOURCE_RELEVANCE_SCORE=0.5  # Filter sources below this relevance (0-1)
REQUIRE_VALID_SOURCES=true      # Retry search if no valid sources found