# ==========================================
# Local Deep Researcher Configuration
# ==========================================
# 
# SETUP INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in your API keys and preferences
# 3. Never commit .env to version control!
#
# ==========================================

# ==========================================
# SEARCH API CONFIGURATION (Required)
# ==========================================
# Choose your search provider
# Options: tavily, duckduckgo, perplexity, searxng
SEARCH_API=tavily

# Tavily API (Recommended for best results)
# Get free key at: https://tavily.com (1000 searches/month free tier)
# Required if SEARCH_API=tavily
TAVILY_API_KEY=tvly-YOUR_API_KEY_HERE

# DuckDuckGo (No API key needed, but lower quality results)
# Automatically used if SEARCH_API=duckduckgo

# Perplexity API (High quality, requires subscription)
# Get key at: https://www.perplexity.ai/settings/api
# Required if SEARCH_API=perplexity
# PERPLEXITY_API_KEY=pplx-YOUR_API_KEY_HERE

# SearXNG (Self-hosted, privacy-focused)
# Required if SEARCH_API=searxng
# SEARXNG_URL=http://localhost:8888

# ==========================================
# LLM CONFIGURATION (Required)
# ==========================================
# Choose your LLM provider
# Options: ollama, lmstudio
LLM_PROVIDER=ollama

# Ollama Configuration
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (check available models with your model server)
# Use the exact name as shown in your model server
LOCAL_LLM=your_model_name

# LMStudio Configuration (alternative to Ollama)
# Uncomment these if using LMStudio instead
# LLM_PROVIDER=lmstudio
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LOCAL_LLM=your-lmstudio-model-name

# ==========================================
# RESEARCH BEHAVIOR (Optional)
# ==========================================
# Number of research iterations (default: 3)
# Higher = more thorough but slower
MAX_WEB_RESEARCH_LOOPS=3

# Fetch full page content (default: false)
# true = more comprehensive but much slower
FETCH_FULL_PAGE=false

# Use tool calling instead of JSON mode (default: false)
# Enable if your model doesn't support JSON mode
USE_TOOL_CALLING=false

# Strip thinking tokens from output (default: true)
# Some models output thinking process tokens that should be removed
STRIP_THINKING_TOKENS=true

# ==========================================
# SOURCE VALIDATION (Optional but Recommended)
# ==========================================
# Minimum relevance score for sources (0.0 to 1.0)
# Sources below this score are filtered out
MIN_SOURCE_RELEVANCE_SCORE=0.5

# Require at least one valid source to proceed (default: true)
# If true, will retry search if no sources meet minimum score
REQUIRE_VALID_SOURCES=true

# Maximum validation retries (default: 2)
# Prevents infinite loops if no good sources are found
MAX_VALIDATION_RETRIES=2

# ==========================================
# ADVANCED CONFIGURATION (Optional)
# ==========================================
# Enable debug logging
# DEBUG=false

# Custom user agent for web requests
# USER_AGENT="Mozilla/5.0 (compatible; LocalDeepResearcher/1.0)"

# Request timeout in seconds
# REQUEST_TIMEOUT=30

# Maximum tokens for LLM responses
# MAX_TOKENS=2000

# Temperature for LLM (0.0 to 1.0)
# Lower = more focused, Higher = more creative
# TEMPERATURE=0.7

# ==========================================
# NOTES
# ==========================================
# - At minimum, you need to configure:
#   1. A search API (SEARCH_API + its API key if required)
#   2. An LLM provider (LLM_PROVIDER + LOCAL_LLM)
#
# - For best results:
#   * Use Tavily for search (most relevant results)
#   * Use a capable local model appropriate for research tasks
#   * Enable source validation (already enabled by default)
#
# - Common issues:
#   * If searches return poor results, try Tavily instead of DuckDuckGo
#   * If model outputs are garbled, enable USE_TOOL_CALLING
#   * If research is too slow, reduce MAX_WEB_RESEARCH_LOOPS
#
# - Security reminder:
#   * Never share your .env file
#   * Never commit it to Git (it's in .gitignore)
#   * Rotate API keys regularly
#   * Use environment-specific keys (dev/prod)